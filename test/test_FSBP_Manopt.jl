@testsnippet FSBP_Manopt begin
    using Manopt
    import Manifolds, ForwardDiff
    using DoubleFloats: Double64
    using LinearAlgebra: norm, eigvals, diag, rank, cross
end

@testitem "FSBP Basic with Manopt.jl" setup=[FSBP_Manopt] begin
    N = 5
    x_min = -1.0
    x_max = 1.0
    source = GlaubitzIskeLampertÖffner2026Basic()
    for compact in (true, false)
        show(IOContext(devnull, :compact => compact), source)
    end

    for T in (Float32, Float64, Double64)
        nodes = collect(LinRange{T}(x_min, x_max, N))
        debug = SummationByPartsOperatorsExtra.default_options(source, true).debug
        options = (;
                   debug = debug,
                   stopping_criterion = StopAfterIteration(1000) |
                                        StopWhenGradientNormLess(eps(T)))
        let basis_functions = [x -> x^i for i in 0:3]
            # Test errors
            @test_throws ArgumentError function_space_operator(basis_functions, nodes,
                                                               source; derivative_order = 2)
            @test_throws ArgumentError function_space_operator(basis_functions, nodes,
                                                               source;
                                                               sparsity_pattern = ones(Bool,
                                                                                       N,
                                                                                       N))
            @test_throws ArgumentError function_space_operator(basis_functions, nodes,
                                                               source; bandwidth = 2)
            @test_throws ArgumentError function_space_operator(basis_functions, nodes,
                                                               source;
                                                               x0 = zeros(3))
            @test_throws ArgumentError function_space_operator(basis_functions, nodes,
                                                               source;
                                                               basis_functions_weights = ones(3))

            D = function_space_operator(basis_functions, nodes, source; options = options)

            @test eltype(D) == T
            @test grid(D) ≈ nodes
            # Manopt.jl seems to have issues to get the gradient accurate enough with Double64
            eps_ = T == Double64 ? eps(Float64) : eps(T)
            @test all(isapprox.(D * ones(N), zeros(N); atol = 10 * eps_))
            @test D * nodes ≈ ones(N)
            @test D * (nodes .^ 2) ≈ 2 * nodes
            @test D * (nodes .^ 3) ≈ 3 * (nodes .^ 2)
            M = mass_matrix(D)
            @test M * D.D + D.D' * M ≈ mass_matrix_boundary(D)
        end

        let basis_functions = [one, identity, exp]
            D = function_space_operator(basis_functions, nodes, source; options = options)

            @test eltype(D) == T
            @test grid(D) ≈ nodes
            # Manopt.jl seems to have issues to get the gradient accurate enough with Double64
            eps_ = T == Double64 ? eps(Float64) : eps(T)
            @test all(isapprox.(D * ones(N), zeros(N); atol = 1e4 * eps_))
            @test all(isapprox.(D * nodes, ones(N); atol = 1e5 * eps_))
            @test all(isapprox.(D * exp.(nodes), exp.(nodes); atol = 1e5 * eps_))
            M = mass_matrix(D)
            @test M * D.D + D.D' * M ≈ mass_matrix_boundary(D)
        end
    end

    # test non-equidistant nodes generated by `nodes = [0.0, rand(8)..., 1.0]`
    nodes = [0.0, 0.01585580467018155, 0.18010381213204507, 0.270467434432868,
        0.37699483985320303, 0.5600831197666554, 0.5698824835924449, 0.623949064816263,
        0.8574665549914025, 1.0]
    N = length(nodes)
    let basis_functions = [one, identity, exp]
        D = function_space_operator(basis_functions, nodes, source)

        @test grid(D) ≈ nodes
        @test all(isapprox.(D * ones(N), zeros(N); atol = 1e-11))
        @test D * nodes ≈ ones(N)
        @test D * exp.(nodes) ≈ exp.(nodes)
        M = mass_matrix(D)
        @test M * D.D + D.D' * M ≈ mass_matrix_boundary(D)
    end
end

@testitem "FSBP Eigenvalue property with Manopt.jl" setup=[FSBP_Manopt] begin
    # Use N = 10 to get an operator, which does not satisfy the eigenvalue property with the unconstrained optimization.
    N = 10
    x_min = -1.0
    x_max = 1.0
    source = GlaubitzIskeLampertÖffner2026EigenvalueProperty()
    for compact in (true, false)
        show(IOContext(devnull, :compact => compact), source)
    end

    function eigenvalue_property_test(D)
        p = diag(mass_matrix(D))
        nu = 1.0
        D_tilde = Matrix(D)
        D_tilde[1, 1] += nu / p[1]
        return eigvals(D_tilde)
    end

    # currently, other types than `Float32` and `Float64` (`BlasReal` in LinearAlgebra.jl) are not supported
    # because `eigen!` is defined only for `BlasReal`.
    for T in (Float32, Float64)
        nodes = collect(LinRange{T}(x_min, x_max, N))
        debug = SummationByPartsOperatorsExtra.default_options(source, true).debug
        options = (;
                   debug = debug,
                   stopping_criterion = StopAfterIteration(10000) |
                                        cross(StopWhenCostLess(10000 * eps(T)^2), 5))
        let basis_functions = [x -> x^i for i in 0:3]
            # Test errors
            @test_throws ArgumentError function_space_operator(basis_functions, nodes,
                                                               source; derivative_order = 2)
            @test_throws ArgumentError function_space_operator(basis_functions, nodes,
                                                               source;
                                                               sparsity_pattern = ones(Bool,
                                                                                       N,
                                                                                       N))
            @test_throws ArgumentError function_space_operator(basis_functions, nodes,
                                                               source; bandwidth = 3)
            @test_throws ArgumentError function_space_operator(basis_functions, nodes,
                                                               source;
                                                               x0 = zeros(3))
            @test_throws ArgumentError function_space_operator(basis_functions, nodes,
                                                               source;
                                                               basis_functions_weights = ones(3))

            D_basic = function_space_operator(basis_functions, nodes,
                                              GlaubitzIskeLampertÖffner2026Basic())
            x0 = get_optimization_entries(D_basic)
            min_real_eigen = 0.1
            @test count(real.(eigenvalue_property_test(D_basic)) .> min_real_eigen) == 6
            @test rank(Matrix(D_basic)) == 8

            D = function_space_operator(basis_functions, nodes, source;
                                        verbose = true, x0 = x0,
                                        options = options,
                                        min_real_eigen = min_real_eigen)
            @test all(real.(eigenvalue_property_test(D)) .> min_real_eigen)
            @test rank(Matrix(D)) == N - 1

            @test eltype(D) == T
            @test grid(D) ≈ nodes
            # Manopt.jl seems to have issues to get the gradient accurate enough with Double64
            eps_ = T == Double64 ? eps(Float64) : eps(T)
            @test all(isapprox.(D * ones(N), zeros(N); atol = 500 * eps_))
            @test D * nodes ≈ ones(N)
            @test D * (nodes .^ 2) ≈ 2 * nodes
            @test D * (nodes .^ 3) ≈ 3 * (nodes .^ 2)
            M = mass_matrix(D)
            @test M * D.D + D.D' * M ≈ mass_matrix_boundary(D)
        end
    end
end

@testitem "FSBP Regularization with Manopt.jl" setup=[FSBP_Manopt] begin
    N = 15
    x_min = -1.0
    x_max = 1.0
    source = GlaubitzIskeLampertÖffner2026Regularized()
    for compact in (true, false)
        show(IOContext(devnull, :compact => compact), source)
    end

    # Don't test with Double64 because Manopt.jl seems to have issues to get the gradient accurate enough
    # it works, but is not more accurate than Float64
    for T in (Float32, Float64)
        nodes = collect(LinRange{T}(x_min, x_max, N))
        debug = SummationByPartsOperatorsExtra.default_options(source, true).debug
        iterations = T == Float64 ? 100 : (T == Float32 ? 64 : 100)
        options = (;
                   debug = debug,
                   stopping_criterion = StopAfterIteration(iterations) |
                                        StopWhenCostLess(10000 * eps(T)^2))
        let basis_functions = [x -> x^i for i in 0:3]
            # Test errors
            @test_throws AssertionError function_space_operator(basis_functions, nodes,
                                                                source)

            D_basic = function_space_operator(basis_functions, nodes,
                                              GlaubitzIskeLampertÖffner2026Basic())
            regularization_functions = [x -> x^4, x -> x^5]
            x0 = get_optimization_entries(D_basic)
            errors_D_basic = norm.([
                                       D_basic * nodes .^ 4 .- 4 .* nodes .^ 3,
                                       D_basic * nodes .^ 5 .- 5 .* nodes .^ 4
                                   ])

            D = function_space_operator(basis_functions, nodes, source;
                                        verbose = true, x0 = x0,
                                        options = options,
                                        regularization_functions = regularization_functions)
            errors_D = norm.([
                                 D * nodes .^ 4 .- 4 .* nodes .^ 3,
                                 D * nodes .^ 5 .- 5 .* nodes .^ 4
                             ])
            @test all(errors_D .< 10 .* errors_D_basic)

            @test eltype(D) == T
            @test grid(D) ≈ nodes

            tol = T == Float64 ? 1e-10 : (T == Float32 ? 1e-5 : 1e-10)
            @test all(isapprox.(D * ones(N), zeros(N); atol = tol))
            @test D * nodes ≈ ones(N)
            @test D * (nodes .^ 2) ≈ 2 * nodes
            @test D * (nodes .^ 3) ≈ 3 * (nodes .^ 2)
            M = mass_matrix(D)
            @test M * D.D + D.D' * M ≈ mass_matrix_boundary(D)
        end
    end
end
