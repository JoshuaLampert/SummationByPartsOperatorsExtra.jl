var documenterSearchIndex = {"docs":
[{"location":"license/#License","page":"License","title":"License","text":"","category":"section"},{"location":"license/","page":"License","title":"License","text":"MIT License","category":"page"},{"location":"license/","page":"License","title":"License","text":"Copyright (c) 2025-present Joshua Lampert <joshua.lampert@uni-hamburg.de> and contributors","category":"page"},{"location":"license/","page":"License","title":"License","text":"Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:","category":"page"},{"location":"license/","page":"License","title":"License","text":"The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.","category":"page"},{"location":"license/","page":"License","title":"License","text":"THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","category":"page"},{"location":"development/#Development","page":"Development","title":"Development","text":"","category":"section"},{"location":"development/","page":"Development","title":"Development","text":"If you have any suggestions or ideas for improvements or new features, we are pleased to accept and discuss issues or if you are willing to contribute, feel free to open a pull request, even if it is only fixing a typo or improving the docs.","category":"page"},{"location":"development/#Changing-SummationByPartsOperatorsExtra.jl-and-running-it-locally","page":"Development","title":"Changing SummationByPartsOperatorsExtra.jl and running it locally","text":"","category":"section"},{"location":"development/","page":"Development","title":"Development","text":"If you plan to edit SummationByPartsOperatorsExtra.jl, you first need to clone a local copy of the repository, which can be done by using git. It is recommended that you create a project, e.g. call it run, inside the repository, where you can add packages that you use during executing and testing SummationByPartsOperatorsExtra.jl, but are not needed by SummationByPartsOperatorsExtra.jl. This way you can keep the Project.toml of the main repository clean. To do so, you can execute the following lines in a terminal:","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"git clone https://github.com/JoshuaLampert/SummationByPartsOperatorsExtra.jl.git\ncd SummationByPartsOperatorsExtra\nmkdir run\ncd run\njulia --project=. -e 'using Pkg; Pkg.develop(PackageSpec(path=\"..\"))' # Install local SummationByPartsOperatorsExtra.jl clone\njulia --project=. -e 'using Pkg; Pkg.add([\"Optim\", \"Meshes\", \"OrdinaryDiffEqSSPRK\", \"KernelInterpolation\", \"Makie\", \"Plots\"])' # Install additional packages","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"If you use other packages for executing SummationByPartsOperatorsExtra.jl, you can add them to the project in the run directory in an analogous way as above. To use the Julia project within run, be sure to start the Julia REPL by","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"julia --project=.","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"if already inside the the run directory or julia --project=run if in the main directory of the repo.","category":"page"},{"location":"development/#Preview-of-the-documentation","page":"Development","title":"Preview of the documentation","text":"","category":"section"},{"location":"development/","page":"Development","title":"Development","text":"If you want to build the documentation locally, you can run","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"julia --project=docs -e 'using Pkg; Pkg.develop(PackageSpec(path=pwd())); Pkg.instantiate()'","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"once from the SummationByPartsOperatorsExtra.jl main directory to tell Documenter.jl to build the documentation of your local clone. To build the documentation, run","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"julia --project=docs --color=yes docs/make.jl","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"The resulting .html files can then be found in docs/build/ and you can look at them by opening them in a browser. For pull requests from the main repository (i.e. not from a fork), the documentation is automatically built and can be previewed under https://JoshuaLampert.github.io/SummationByPartsOperatorsExtra.jl/previews/PRXXX/ where XXX is the number of the pull request.","category":"page"},{"location":"ref/#SummationByPartsOperatorsExtra.jl-API","page":"Reference","title":"SummationByPartsOperatorsExtra.jl API","text":"","category":"section"},{"location":"ref/#SummationByPartsOperatorsExtra.SummationByPartsOperatorsExtra","page":"Reference","title":"SummationByPartsOperatorsExtra.SummationByPartsOperatorsExtra","text":"SummationByPartsOperatorsExtra\n\nSummationByPartsOperatorsExtra.jl is a Julia package that implements some extra functionality for the package SummationByPartsOperators.jl. SummationByPartsOperatorsExtra.jl is still in an early stage of development and is meant to be used for research purposes. Maybe some parts of the package will be moved to SummationByPartsOperators.jl in the future. Until now, the package focuses on the implementation of function space summation-by-parts operators in one and multiple dimensions and on subcell summation-by-parts operators.\n\nSee also: SummationByPartsOperatorsExtra.jl\n\n\n\n\n\n","category":"module"},{"location":"ref/#SummationByPartsOperatorsExtra.AnalysisCallback","page":"Reference","title":"SummationByPartsOperatorsExtra.AnalysisCallback","text":"AnalysisCallback(semi; interval = 0, dt = nothing)\n\nAnalyze the numerical solution either every interval accepted time steps or every dt in terms of integration time. You can only pass either interval or dt, but not both at the same time. The analyzed quantities are computed by analyze_quantities defined for each equation type. The resulting quantities can be accessed via the quantities function, and the corresponding time values via the tstops function.\n\n\n\n\n\n","category":"type"},{"location":"ref/#SummationByPartsOperatorsExtra.GlaubitzIskeLampertÖffner2025","page":"Reference","title":"SummationByPartsOperatorsExtra.GlaubitzIskeLampertÖffner2025","text":"GlaubitzIskeLampertÖffner2025()\n\nMultidimensional function space SBP (MFSBP) operators given in\n\nGlaubitz, Iske, Lampert, Öffner (2025) Efficient construction and application of multi-dimensional summation-by-parts operators to global radial basis function methods TODO\n\nSee multidimensional_function_space_operator.\n\n\n\n\n\n","category":"type"},{"location":"ref/#SummationByPartsOperatorsExtra.GlaubitzLampertNordströmWinters2025","page":"Reference","title":"SummationByPartsOperatorsExtra.GlaubitzLampertNordströmWinters2025","text":"GlaubitzLampertNordströmWinters2025()\n\nSub-cell SBP operators given in\n\nGlaubitz, Lampert, Nordström, Winters (2025): Provable energy stable overset grid methods using sub-cell summation-by-parts operators: One-dimensional linear advection equations. TODO\n\nSee subcell_operator.\n\n\n\n\n\n","category":"type"},{"location":"ref/#SummationByPartsOperatorsExtra.MultidimensionalLinearAdvectionNonperiodicSemidiscretization","page":"Reference","title":"SummationByPartsOperatorsExtra.MultidimensionalLinearAdvectionNonperiodicSemidiscretization","text":"MultidimensionalLinearAdvectionNonperiodicSemidiscretization(D, a, bc)\n\nA semidiscretization of the linear advection equation     partial_t u(x t) + acdot nabla u(x t) = 0 with boundary conditions bc(x, t).\n\nD is a multidimensional SBP derivative operator, and a is a tuple of the constant coefficients.\n\n\n\n\n\n","category":"type"},{"location":"ref/#SummationByPartsOperatorsExtra.SubcellOperator","page":"Reference","title":"SummationByPartsOperatorsExtra.SubcellOperator","text":"SubcellOperator{T}\nSubcellOperator(nodes::Vector{T}, x_M::T,\n                weights_left::Vector{T}, weights_right::Vector{T},\n                Q_left::QType, Q_right::QType,\n                B_left::BType, B_right::BType,\n                accuracy_order::Int,\n                source::SourceOfCoefficients) where {T <: Real,\n                                                     QType <: AbstractMatrix{T},\n                                                     BType <: AbstractMatrix{T},\n                                                     SourceOfCoefficients}\n\nA sub-cell derivative operator on a non-periodic grid with scalar type T. A sub-cell operator consists of two parts, a left and a right part, which are defined on the left and right sub-cells of the grid. Each of the two parts satisfy a summation-by-parts property on their respecting sub-cell. The whole operator satisfies a summation-by-parts property on the whole grid.\n\nThe whole operator follows the general interface of a derivative operator, e.g., implementing matrix-vector multiplication, integration, and the mass matrix. To obtain the derivative matrix D = P^-1(Q_L + Q_R) associated to the sub-cell operator, use the function derivative_matrix. The left and right mass matrices can be obtained with the functions mass_matrix_left and mass_matrix_right, respectively. Similarly, the boundary mass matrices can be obtained with the functions mass_matrix_boundary_left and mass_matrix_boundary_right.\n\nSee also subcell_operator and GlaubitzIskeLampertÖffner2025.\n\nReferences:\n\nGlaubitz, Lampert, Nordström, Winters (2025): Provable energy stable overset grid methods using sub-cell summation-by-parts operators: One-dimensional linear advection equations. TODO\n\n\n\n\n\n","category":"type"},{"location":"ref/#SummationByPartsOperatorsExtra.compute_moments_boundary-Tuple{Any, Any, Any}","page":"Reference","title":"SummationByPartsOperatorsExtra.compute_moments_boundary","text":"compute_moments_boundary(functions, nodes, normals)\ncompute_moments_boundary(functions, D::AbstractDerivativeOperator)\ncompute_moments_boundary(functions, geometry::Meshes.Geometry)\n\nCompute the moments, i.e., the integrals of the product of two basis functions weighted by the normal direction of the direction. For each direction, it computes a K \times K matrix, where K is the number of functions and returns a tuple of these matrices. In one dimension, nodes and normals can be passed. You can also pass a derivative operator D or a Geometry object from Meshes.jl. Note that the latter is defined in a package extension of MeshIntegrals.jl and therefore requires loading that package before.\n\n\n\n\n\n","category":"method"},{"location":"ref/#SummationByPartsOperatorsExtra.derivative_matrix-Tuple{SubcellOperator}","page":"Reference","title":"SummationByPartsOperatorsExtra.derivative_matrix","text":"derivative_matrix(Dop::SubcellOperator)\n\nReturns the derivative matrix D = P^-1(Q_L + Q_R) associated to the sub-cell operator Dop.\n\n\n\n\n\n","category":"method"},{"location":"ref/#SummationByPartsOperatorsExtra.function_space_operator","page":"Reference","title":"SummationByPartsOperatorsExtra.function_space_operator","text":"function_space_operator(basis_functions, nodes, source;\n                        derivative_order = 1, accuracy_order = 0,\n                        basis_functions_weights = ones(length(basis_functions)),\n                        bandwidth = length(nodes) - 1, size_boundary = 2 * bandwidth,\n                        different_values = true, sparsity_pattern = nothing,\n                        opt_alg = Optim.LBFGS(), options = Optim.Options(g_tol = 1e-14, iterations = 10000),\n                        autodiff = :forward, x0 = nothing, verbose = false)\n\nConstruct an operator that represents a first-derivative operator in a function space spanned by the basis_functions, which is an iterable of functions. The operator is constructed on the interval [x_min, x_max] with the nodes nodes, where x_min is taken as the minimal value in nodes and x_max the maximal value. Note that the nodes will be sorted internally. The accuracy_order is the order of the accuracy of the operator, which can optionally be passed, but does not have any effect on the operator.\n\nThe operator is constructed solving an optimization problem with Optim.jl. You can specify the optimization algorithm, the options for the optimization problem, and the autodiff mode with the keyword arguments opt_alg, options, and autodiff respectively, see also the documentation of Optim.jl about configurable options and automatic differentiation. In this case, reverse mode automatic differentiation is usually significantly faster than forward mode. We recommend using autodiff = ADTypes.AutoMooncake(; config = nothing) or autodiff = ADTypes.AutoEnzyme(; mode = Enzyme.Reverse, function_annotation = Enzyme.Duplicated). Note that you need to import the package ADTypes as well as the corresponding autodiff (i.e., Mooncake or Enzyme) package to use these modes.\n\nThe initial guess for the optimization problem can be passed with the keyword argument x0, which is optional. If nothing is passed, a default initial guess (zeros for the entries of the differentiation matrix and equal values for all the weights) is used.\n\nYou can weight each basis function with the keyword argument basis_functions_weights, which is a vector of weights for each basis function. The default is a vector of ones, which means that all basis functions are equally weighted. This can be used to, e.g., enforce exactness for certain basis functions (high weights), but allow non-exactness for others only minimizing the error (low weights).\n\nThere are two alternative ways to enforce sparsity of the resulting operator. The first is by passing a matrix sparsity_pattern that is a matrix of zeros and ones, where the ones indicate the non-zero entries of the operator. This matrix should be symmetric or UpperTriangular and have zeros on the diagonal.\n\nThe second way is to use a banded-block structure for the operator as is common, e.g., in finite difference methods. The keyword arguments bandwidth and size_boundary specify the bandwidth and the size of the boundary blocks of the operator, where the default of bandwidth is set to length(nodes) - 1, i.e., a dense operator (in this case size_boundary is ignored). To construct a sparse operator, you can set the bandwidth to a smaller value, such that 2 * size_boundary + bandwidth < length(nodes), which is a requirement for the boundary blocks in the upper left and lower right of the resulting operator. If different_values is set to true all the entries in the upper right triangle of S (the skew symmetric part of D) are different, which is generally meaningful for non-equidistant nodes and general bases, if it is false the entries of the stencil are repeated in the central part and the two boundary closures share their values (makes sense for uniformly distributed nodes and, e.g., a polynomial basis). The keyword argument different_values is ignored for dense operators.\n\nThe keyword argument verbose can be set to true to print information about the optimization process.\n\nThe operator that is returned follows the general interface. Currently, it is wrapped in a SummationByPartsOperators.MatrixDerivativeOperator, but this might change in the future. In order to use this function, the package Optim must be loaded.\n\nSee also SummationByPartsOperators.GlaubitzNordströmÖffner2023.\n\ncompat: Julia 1.9\nThis function requires at least Julia 1.9.\n\nwarning: Experimental implementation\nThis is an experimental feature and may change in future releases.\n\n\n\n\n\n","category":"function"},{"location":"ref/#SummationByPartsOperatorsExtra.get_multidimensional_optimization_entries-Tuple{Any}","page":"Reference","title":"SummationByPartsOperatorsExtra.get_multidimensional_optimization_entries","text":"get_multidimensional_optimization_entries(D;\n                                          bandwidth = div(accuracy_order(D), 2),\n                                          size_boundary = SummationByPartsOperators.lower_bandwidth(D) + 1,\n                                          different_values = false,\n                                          sparsity_pattern = nothing)\n\nGet the entries to optimize for in an optimization-based construction procedure of multidimensional summation-by-parts operators from a derivative operator D. It contains the entries of the skew-symmetric part of the operator D, the entries of the diagonal mass matrix M, and the entries of the diagonal boundary mass matrix. For more details, see multidimensional_function_space_operator. The output can be passed as initial values to the optimization problem as x0.\n\n\n\n\n\n","category":"method"},{"location":"ref/#SummationByPartsOperatorsExtra.get_nsigma-Tuple{Any}","page":"Reference","title":"SummationByPartsOperatorsExtra.get_nsigma","text":"get_nsigma(N; bandwidth = N - 1,\n           size_boundary = 2 * bandwidth, different_values = true,\n           sparsity_pattern = nothing)\n\nGet the number of unique non-zero entries in a skew-symmetric matrix. If bandwidth is N - 1, the whole upper right triangle is used. If bandwidth is smaller, a block-banded structure with boundary blocks of size size_boundary is used and a banded matrix with bandwidth bandwidth in the middle. If different_values is false, the stencils are repeating. If sparsity_pattern is given, the number of non-zero entries in the sparsity pattern is returned. The sparsity pattern is assumed to be a UpperTriangular matrix with zeros on the diagonal.\n\n\n\n\n\n","category":"method"},{"location":"ref/#SummationByPartsOperatorsExtra.get_optimization_entries-Tuple{Any}","page":"Reference","title":"SummationByPartsOperatorsExtra.get_optimization_entries","text":"get_optimization_entries(D;\n                         bandwidth = div(accuracy_order(D), 2),\n                         size_boundary = SummationByPartsOperators.lower_bandwidth(D) + 1,\n                         different_values = false,\n                         sparsity_pattern = nothing)\n\nGet the entries to optimize for in an optimization-based construction procedure of summation-by-parts operators from a derivative operator D. It contains the entries of the skew-symmetric part of the operator D and the entries of the diagonal mass matrix M. For more details, see function_space_operator. The output can be passed as initial values to the optimization problem as x0.\n\n\n\n\n\n","category":"method"},{"location":"ref/#SummationByPartsOperatorsExtra.get_sparsity_pattern-Tuple{Any}","page":"Reference","title":"SummationByPartsOperatorsExtra.get_sparsity_pattern","text":"get_sparsity_pattern(S)\nget_sparsity_pattern(D::AbstractNonperiodicDerivativeOperator)\nget_sparsity_pattern(D::AbstractMultidimensionalMatrixDerivativeOperator{2})\n\nIf S is a (skew-symmetric) matrix, this function returns the sparsity pattern of S as a UpperTriangular matrix. If D is a one-dimensional derivative operator, this function returns the sparsity pattern of the skew-symmetric part of D. If D is a two-dimensional derivative operator, this function returns a tuple of the sparsity patterns of the skew-symmetric parts of D in each direction.\n\n\n\n\n\n","category":"method"},{"location":"ref/#SummationByPartsOperatorsExtra.grid_left-Tuple{SubcellOperator}","page":"Reference","title":"SummationByPartsOperatorsExtra.grid_left","text":"grid_left(D::SubcellOperator)\n\nReturns the grid associated to the left part of the sub-cell operator D.\n\n\n\n\n\n","category":"method"},{"location":"ref/#SummationByPartsOperatorsExtra.grid_right-Tuple{SubcellOperator}","page":"Reference","title":"SummationByPartsOperatorsExtra.grid_right","text":"grid_right(D::SubcellOperator)\n\nReturns the grid associated to the right part of the sub-cell operator D.\n\n\n\n\n\n","category":"method"},{"location":"ref/#SummationByPartsOperatorsExtra.left_projection_left-Tuple{SubcellOperator}","page":"Reference","title":"SummationByPartsOperatorsExtra.left_projection_left","text":"left_projection_left(D::SubcellOperator)\nleft_projection_right(D::SubcellOperator)\nright_projection_left(D::SubcellOperator)\nright_projection_right(D::SubcellOperator)\n\nReturns the left and right projection operators associated to the left and right parts of the sub-cell operator D.\n\n\n\n\n\n","category":"method"},{"location":"ref/#SummationByPartsOperatorsExtra.mass_matrix_boundary_left-Tuple{SubcellOperator}","page":"Reference","title":"SummationByPartsOperatorsExtra.mass_matrix_boundary_left","text":"mass_matrix_boundary_left(D::SubcellOperator)\n\nReturns the mass matrix associated to the left boundary of the sub-cell operator D.\n\n\n\n\n\n","category":"method"},{"location":"ref/#SummationByPartsOperatorsExtra.mass_matrix_boundary_right-Tuple{SubcellOperator}","page":"Reference","title":"SummationByPartsOperatorsExtra.mass_matrix_boundary_right","text":"mass_matrix_boundary_right(D::SubcellOperator)\n\nReturns the mass matrix associated to the right boundary of the sub-cell operator D.\n\n\n\n\n\n","category":"method"},{"location":"ref/#SummationByPartsOperatorsExtra.mass_matrix_left-Tuple{SubcellOperator}","page":"Reference","title":"SummationByPartsOperatorsExtra.mass_matrix_left","text":"mass_matrix_left(D::SubcellOperator)\n\nReturns the mass matrix associated to the left part of the sub-cell operator D.\n\n\n\n\n\n","category":"method"},{"location":"ref/#SummationByPartsOperatorsExtra.mass_matrix_right-Tuple{SubcellOperator}","page":"Reference","title":"SummationByPartsOperatorsExtra.mass_matrix_right","text":"mass_matrix_right(D::SubcellOperator)\n\nReturns the mass matrix associated to the right part of the sub-cell operator D.\n\n\n\n\n\n","category":"method"},{"location":"ref/#SummationByPartsOperatorsExtra.multidimensional_function_space_operator","page":"Reference","title":"SummationByPartsOperatorsExtra.multidimensional_function_space_operator","text":"multidimensional_function_space_operator(basis_functions, nodes, boundary_indices, normals, moments, vol, source;\n                                         derivative_order = 1, accuracy_order = 0,\n                                         bandwidth = length(nodes) - 1, size_boundary = 2 * bandwidth,\n                                         different_values = true, sparsity_pattern = nothing,\n                                         opt_alg = Optim.LBFGS(), options = Optim.Options(g_tol = 1e-14, iterations = 10000),\n                                         autodiff = :forward, x0 = nothing, verbose = false)\n\nConstruct a SummationByPartsOperators.MultidimensionalMatrixDerivativeOperator that represents a first-derivative operator in a function space spanned by the basis_functions, which is an iterable of functions. The operator is constructed on the scattered nodes nodes. They should be provided as an iterable of SVector{Dim, T}. The boundary_indices is a vector of indies that indicates, which nodes are on the boundary. normals is a vector of SVector{Dim, T} that contains the normal vectors of the boundary nodes. The moments are a Tuple of matrices that represent the moments of the basis functions in each direction. The total volume of the domain is given by vol.\n\nThe accuracy_order is the order of the accuracy of the operator, which can optionally be passed, but does not have any effect on the operator.\n\nThe operator is constructed solving an optimization problem with Optim.jl. You can specify the optimization algorithm, the options for the optimization problem, and the autodiff mode with the keyword arguments opt_alg, options, and autodiff respectively, see also the documentation of Optim.jl about configurable options and automatic differentiation. In this case, reverse mode automatic differentiation is usually significantly faster than forward mode. We recommend using autodiff = ADTypes.AutoMooncake(; config = nothing) or autodiff = ADTypes.AutoEnzyme(; mode = Enzyme.Reverse, function_annotation = Enzyme.Duplicated). Note that you need to import the package ADTypes as well as the corresponding autodiff (i.e., Mooncake or Enzyme) package to use these modes.\n\nThe initial guess for the optimization problem can be passed with the keyword argument x0, which is optional. If nothing is passed, a default initial guess (zeros for the entries of the differentiation matrix and equal values for all the weights and boundary weights) is used.\n\nThere are two alternative ways to enforce sparsity of the resulting operator. The first is by passing a matrix sparsity_pattern that is a matrix of zeros and ones, where the ones indicate the non-zero entries of the operator. This matrix should be symmetric or UpperTriangular and have zeros on the diagonal.\n\nThe second way is to use a banded-block structure for the operator as is common, e.g., in finite difference methods. The keyword arguments bandwidth and size_boundary specify the bandwidth and the size of the boundary blocks of the differentiation matrices in each direction, where the default of bandwidth is set to length(nodes) - 1, i.e., dense operators (in this case size_boundary is ignored). To construct sparse operators, you can set the bandwidth to a smaller value, such that 2 * size_boundary + bandwidth < length(nodes), which is a requirement for the boundary blocks in the upper left and lower right of the resulting operator. If different_values is set to true all the entries in the upper right triangle of all matrices S (the skew symmetric parts of the differentiation matrices D) are different, which is generally meaningful for non-equidistant nodes and general bases, if it is false the entries of the stencil are repeated in the central part and the two boundary closures share their values (makes sense for uniformly distributed nodes and, e.g., a polynomial basis). The keyword argument different_values is ignored for dense operators. The parameters bandwidth, size_boundary, and different_values are only used if sparsity_pattern is not provided.\n\nThe keyword argument verbose can be set to true to print information about the optimization process.\n\nIn order to use this function, the package Optim must be loaded.\n\nSee also GlaubitzIskeLampertÖffner2025.\n\ncompat: Julia 1.9\nThis function requires at least Julia 1.9.\n\nwarning: Experimental implementation\nThis is an experimental feature and may change in future releases.\n\n\n\n\n\n","category":"function"},{"location":"ref/#SummationByPartsOperatorsExtra.neighborhood_sparsity_pattern-Tuple{Any, Any}","page":"Reference","title":"SummationByPartsOperatorsExtra.neighborhood_sparsity_pattern","text":"neighborhood_sparsity_pattern(nodes, lengths)\n\nFor a given set of nodes in a multi-dimensional space, this function computes the sparsity pattern of the differentiation matrices, which only includes non-zero entries at nodes, which are within a certain ellipsoid neighborhood. lengths is a tuple of length d (dimension) representing the lengths of an ellipsoid indicating, which nodes are counted as neighbors. For example, for a differentiation matrix in x direction, it makes sense to use a larger length in x direction than in y direction.\n\n\n\n\n\n","category":"method"},{"location":"ref/#SummationByPartsOperatorsExtra.plot_nodes","page":"Reference","title":"SummationByPartsOperatorsExtra.plot_nodes","text":"plot_nodes(nodes_inner, nodes_boundary; corners = nothing, kwargs...)\nplot_nodes(nodes, boundary_indices::Vector{Int}; corner_indices = nothing,\n           kwargs...)\nplot_nodes(D; kwargs...)\n\nPlot the nodes of a multidimensional derivative operator D. The interior nodes nodes_inner are plotted and the boundary nodes nodes_boundary are plotted in different colors. If corner_indices are provided, the corners are also plotted in a different color. Additional keyword arguments are passed to viz from Meshes.jl, see the documentation. The function returns the current figure.\n\n\n\n\n\n","category":"function"},{"location":"ref/#SummationByPartsOperatorsExtra.plot_normals","page":"Reference","title":"SummationByPartsOperatorsExtra.plot_normals","text":"plot_normals(nodes_boundary, normals; kwargs...)\nplot_normals(D; kwargs...)\n\nPlot the normals of a multidimensional derivative operator D. The boundary nodes nodes_boundary are plotted and the normals are plotted as arrows. Additional keyword arguments are passed to viz from Meshes.jl, see the documentation. The function returns the current figure.\n\n\n\n\n\n","category":"function"},{"location":"ref/#SummationByPartsOperatorsExtra.plot_sparsity_pattern","page":"Reference","title":"SummationByPartsOperatorsExtra.plot_sparsity_pattern","text":"plot_sparsity_pattern(sparsity_pattern, nodes, node_index)\n\nPlot the sparsity_pattern, which is a boolean matrix of length length(nodes) x length(nodes), where nodes is a set of nodes. The node_index is the index of the node in nodes that is used to plot the sparsity pattern around that node, i.e., it will be plotted as red, while all neighboring nodes according to the sparsity_pattern are plotted as green dots and the remaining nodes are plotted as blue dots.\n\n\n\n\n\n","category":"function"},{"location":"ref/#SummationByPartsOperatorsExtra.quantities-Tuple{DiscreteCallback{<:Any, <:AnalysisCallback}}","page":"Reference","title":"SummationByPartsOperatorsExtra.quantities","text":"quantities(analysis_callback)\n\nReturn the computed quantities for each time step.\n\n\n\n\n\n","category":"method"},{"location":"ref/#SummationByPartsOperatorsExtra.subcell_operator","page":"Reference","title":"SummationByPartsOperatorsExtra.subcell_operator","text":"subcell_operator(basis_functions, nodes, x_M, source;\n                 derivative_order = 1, accuracy_order = 0,\n                 bandwidths = [N_L - 1, N_R - 1], size_boundaries = 2 .* bandwidths,\n                 different_values = [true, true], sparsity_patterns = [nothing, nothing],\n                 M_local_approximation = [N_L, N_R],\n                 opt_alg = Optim.LBFGS(), options = Optim.Options(g_tol = 1e-14, iterations = 10000),\n                 autodiff = :forward, x0 = nothing, verbose = false)\n\nConstruct a sub-cell operator in a function space spanned by the basis_functions, which is an iterable of functions. The operator is constructed on the interval [x_min, x_max] with the nodes nodes, where x_min is taken as the minimal value in nodes and x_max the maximal value. Note that the nodes will be sorted internally. The left part of the sub-cell operator consists of the nodes, which are smaller than x_M and the right part of the nodes, which are bigger than x_M. The accuracy_order is the order of the accuracy of the operator, which can optionally be passed, but does not have any effect on the operator.\n\nThe operator is constructed solving an optimization problem with Optim.jl. You can specify the optimization algorithm, the options for the optimization problem, and the autodiff mode with the keyword arguments opt_alg, options, and autodiff respectively, see also the documentation of Optim.jl about configurable options and automatic differentiation. In this case, reverse mode automatic differentiation is usually significantly faster than forward mode. We recommend using autodiff = ADTypes.AutoMooncake(; config = nothing) or autodiff = ADTypes.AutoEnzyme(; mode = Enzyme.Reverse, function_annotation = Enzyme.Duplicated). Note that you need to import the package ADTypes as well as the corresponding autodiff (i.e., Mooncake or Enzyme) package to use these modes.\n\nThe initial guess for the optimization problem can be passed with the keyword argument x0, which is optional. If nothing is passed, a default initial guess (zeros for the entries of the differentiation matrix and equal values for all the weights) is used.\n\nThere are two alternative ways to enforce sparsity of the resulting left and right operator. The first is by passing matrices sparsity_pattern that are matrices of zeros and ones each, where the ones indicate the non-zero entries of the left and operator, respectively. The matrices should be symmetric or UpperTriangular and have zeros on the diagonal.\n\nThe second way is to use a banded-block structure for the parts of the operator as is common, e.g., in finite difference methods. The keyword arguments bandwidths and size_boundaries specify the bandwidth and the size of the boundary blocks of the operators, where the default of bandwidths is set to the number of nodes in the left and right sub-cell minus one, i.e., a dense operator (in this case size_boundaries is ignored). To construct a sparse operator, you can set the bandwidth to a smaller value, such that 2 * size_boundaries[i] + bandwidths[i] < N_{L/R}, which is a requirement for the boundary blocks in the upper left and lower right of the resulting operator. If different_values is set to true all the entries in the upper right triangle of S (the skew symmetric parts of the differentiation matrix blocks) are different, which is generally meaningful for non-equidistant nodes and general bases, if it is false the entries of the stencil are repeated in the central part and the two boundary closures share their values (makes sense for uniformly distributed nodes and, e.g., a polynomial basis). The keyword argument different_values is ignored for dense operators.\n\nYou can use the keyword argument M_local_approximation to specify the number of points used for local approximations of the discrete projections. The default is to use the number of nodes in the left and right sub-cell, respectively. To use an interpolation, you can set M_local_approximation to [K, K], where K is the number of basis functions.\n\nThe keyword argument verbose can be set to true to print information about the optimization process.\n\nReturns a SubcellOperator object.\n\nSee also GlaubitzLampertNordströmWinters2025.\n\ncompat: Julia 1.9\nThis function requires at least Julia 1.9.\n\nwarning: Experimental implementation\nThis is an experimental feature and may change in future releases.\n\n\n\n\n\n","category":"function"},{"location":"ref/#SummationByPartsOperatorsExtra.tstops-Tuple{DiscreteCallback{<:Any, <:AnalysisCallback}}","page":"Reference","title":"SummationByPartsOperatorsExtra.tstops","text":"tstops(analysis_callback)\n\nReturn the time values that correspond to the saved values of the quantities.\n\n\n\n\n\n","category":"method"},{"location":"#SummationByPartsOperatorsExtra.jl","page":"Home","title":"SummationByPartsOperatorsExtra.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: Docs-dev) (Image: Build Status) (Image: codecov) (Image: Aqua QA) (Image: License: MIT)","category":"page"},{"location":"","page":"Home","title":"Home","text":"SummationByPartsOperatorsExtra.jl is a Julia package that implements some extra functionality for the package SummationByPartsOperators.jl. SummationByPartsOperatorsExtra.jl is still in an early stage of development and is meant to be used for research purposes. Maybe some parts of the package will be moved to SummationByPartsOperators.jl in the future. Until now, the package focuses on the implementation of function space summation-by-parts operators in one and multiple dimensions and on subcell summation-by-parts operators.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you have not yet installed Julia, then you first need to download Julia. Please follow the instructions for your operating system. SummationByPartsOperatorsExtra.jl works with Julia v1.11 and newer. You can install SummationByPartsOperatorsExtra.jl by executing the following commands from the Julia REPL","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using Pkg\n\njulia> Pkg.add(\"https://github.com/JoshuaLampert/SummationByPartsOperatorsExtra.jl\")","category":"page"},{"location":"#Usage","page":"Home","title":"Usage","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"In the Julia REPL, first load the package SummationByPartsOperatorsExtra.jl","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using SummationByPartsOperatorsExtra","category":"page"},{"location":"","page":"Home","title":"Home","text":"SummationByPartsOperatorsExtra.jl is built on top of the package SummationByPartsOperators.jl and exports all the functions and types of the package.","category":"page"},{"location":"#Authors","page":"Home","title":"Authors","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The package is developed and maintained by Joshua Lampert (University of Hamburg).","category":"page"},{"location":"#License-and-contributing","page":"Home","title":"License and contributing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"SummationByPartsOperatorsExtra.jl is published under the MIT license (see License). We are pleased to accept contributions from everyone, preferably in the form of a PR.","category":"page"}]
}
